#!/usr/bin/env python3
"""
NI Sample Chainer - Main Application

Processes audio files and creates sample chains optimized for the Elektron Digitakt 2.
"""

import sys
from pathlib import Path
from typing import Dict, Any, Optional, List
import numpy as np
import yaml
import click

# Add src directory to path for imports to work
src_path = Path(__file__).parent
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

# Import our modules
from utils.sample_chain_config import SampleChainConfig
from utils.smart_chain_planner import SmartChainPlanner
from audio_processing.sample_chain_builder import SampleChainBuilder
from audio_processing.chain_exporter import ChainExporter
from audio_processing.audio_processor import AudioProcessor
from audio_processing.audio_converter import AudioConverter

def _generate_markdown_summary(built_chains: List[Dict[str, Any]], output_path: Path, input_dir: str = None) -> None:
    """
    Generate a markdown summary of all generated chains.
    
    Args:
        built_chains: List of built chain dictionaries
        output_path: Path to save the markdown file
        input_dir: Input directory path for calculating relative paths
    """
    with open(output_path, 'w') as f:
        f.write("# Sample Chain Summary\n\n")
        f.write("*Generated by NI Sample Chainer*\n\n")
        
        # Count chains by type
        hihat_chains = [c for c in built_chains if c.get('name', '').startswith('hats')]
        regular_chains = [c for c in built_chains if not c.get('name', '').startswith('hats')]
        
        f.write(f"## Overview\n\n")
        f.write(f"- **Total Chains**: {len(built_chains)}\n")
        f.write(f"- **Hi-hat Chains**: {len(hihat_chains)}\n")
        f.write(f"- **Regular Chains**: {len(regular_chains)}\n")
        f.write(f"- **Total Samples**: {sum(c['metadata']['sample_count'] for c in built_chains)}\n\n")
        
        # Hi-hat chains
        if hihat_chains:
            f.write("## Hi-hat Chains (with closed/open interleaving)\n\n")
            for chain in hihat_chains:
                metadata = chain['metadata']
                f.write(f"### {chain.get('name', 'unknown')}\n\n")
                f.write(f"- **Samples**: {metadata['sample_count']}\n")
                f.write(f"- **Duration**: {metadata['estimated_duration_seconds']:.3f}s\n")
                f.write(f"- **Files**:\n")
                
                # Show only the enclosing folder name and filename
                original_files = chain.get('original_files', [])
                for file_path in original_files:
                    if isinstance(file_path, str):
                        # Convert to Path object for easier manipulation
                        path_obj = Path(file_path)
                        # Get just the parent folder name and filename
                        if len(path_obj.parts) >= 2:
                            folder_name = path_obj.parts[-2]
                            filename = path_obj.name
                            display_path = f"{folder_name}/{filename}"
                        else:
                            display_path = path_obj.name
                        f.write(f"  - {display_path}\n")
                    else:
                        # Already a Path object
                        if len(file_path.parts) >= 2:
                            folder_name = file_path.parts[-2]
                            filename = file_path.name
                            display_path = f"{folder_name}/{filename}"
                        else:
                            display_path = file_path.name
                        f.write(f"  - {display_path}\n")
                f.write("\n")
        
        # Regular chains
        if regular_chains:
            f.write("## Regular Chains (by directory structure)\n\n")
            for chain in regular_chains:
                metadata = chain['metadata']
                f.write(f"### {chain.get('name', 'unknown')}\n\n")
                f.write(f"- **Samples**: {metadata['sample_count']}\n")
                f.write(f"- **Duration**: {metadata['estimated_duration_seconds']:.3f}s\n")
                f.write(f"- **Files**:\n")
                
                # Show only the enclosing folder name and filename
                original_files = chain.get('original_files', [])
                for file_path in original_files:
                    if isinstance(file_path, str):
                        # Convert to Path object for easier manipulation
                        path_obj = Path(file_path)
                        # Get just the parent folder name and filename
                        if len(path_obj.parts) >= 2:
                            folder_name = path_obj.parts[-2]
                            filename = path_obj.name
                            display_path = f"{folder_name}/{filename}"
                        else:
                            display_path = path_obj.name
                        f.write(f"  - {display_path}\n")
                    else:
                        # Already a Path object
                        if len(file_path.parts) >= 2:
                            folder_name = file_path.parts[-2]
                            filename = file_path.name
                            display_path = f"{folder_name}/{filename}"
                        else:
                            display_path = file_path.name
                        f.write(f"  - {display_path}\n")
                f.write("\n")
        
        f.write("*Generated by NI Sample Chainer*\n")

def _dry_run_processing(audio_files: List[Path], config: SampleChainConfig, input_dir: str = None) -> Dict[str, Any]:
    """
    Show what would be created without actually processing files.
    
    Args:
        audio_files: List of audio files to process
        config: Configuration object
        input_dir: Input directory path
        
    Returns:
        Dictionary with dry run results
    """
    print("\nüîç DRY RUN MODE - No files will be processed")
    print("=" * 60)
    
    # Plan sample chains
    planner = SmartChainPlanner(config)
    chains = planner.plan_smart_chains(audio_files)
    
    print(f"üìä Would create {len(chains)} sample chains:\n")
    
    # Group chains by type
    hihat_chains = [(k, v) for k, v in chains.items() if k.startswith('hats')]
    regular_chains = [(k, v) for k, v in chains.items() if not k.startswith('hats')]
    
    # Display hi-hat chains
    if hihat_chains:
        print("ü•Å HI-HAT CHAINS (with closed/open interleaving):")
        print("-" * 50)
        for chain_key, chain_data in hihat_chains:
            metadata = chain_data['metadata']
            sample_count = metadata.get('sample_count', 0)
            estimated_size = metadata.get('estimated_file_size_mb', 0)
            actual_duration = metadata.get('estimated_duration_seconds', 0)
            
            print(f"  {chain_key}: {sample_count} samples")
            print(f"    Closed: {metadata.get('closed_count', 0)}, Open: {metadata.get('open_count', 0)}")
            print(f"    Hat names: {', '.join(metadata.get('hat_names', []))}")
            print(f"    Est. size: {estimated_size:.2f}MB")
            print(f"    Longest sample: {actual_duration:.2f}s")
            
            # Show first few files
            for i, file_path in enumerate(chain_data['files'][:4], 1):
                if isinstance(file_path, str):
                    filename = file_path.split('/')[-1]
                else:
                    filename = file_path.name
                
                if 'closed' in filename.lower():
                    print(f"      {i}. üîí {filename}")
                elif 'open' in filename.lower():
                    print(f"      {i}. üîì {filename}")
                else:
                    print(f"      {i}. {filename}")
            
            if len(chain_data['files']) > 4:
                print(f"      ... and {len(chain_data['files']) - 4} more files")
            print()
    
    # Display regular chains
    if regular_chains:
        print("üéµ REGULAR CHAINS (by directory structure):")
        print("-" * 50)
        for chain_key, chain_data in regular_chains:
            metadata = chain_data['metadata']
            sample_count = metadata.get('sample_count', 0)
            estimated_size = metadata.get('estimated_file_size_mb', 0)
            
            print(f"  {chain_key}: {sample_count} samples")
            print(f"    Est. size: {estimated_size:.2f}MB")
            
            # Show first few files
            for i, file_path in enumerate(chain_data['files'][:3], 1):
                if isinstance(file_path, str):
                    filename = file_path.split('/')[-1]
                else:
                    filename = file_path.name
                print(f"      {i}. {filename}")
            
            if len(chain_data['files']) > 3:
                print(f"      ... and {len(chain_data['files']) - 3} more files")
            print()
    
    # Summary
    print("üìà SUMMARY:")
    print(f"  Total files to process: {len(audio_files)}")
    print(f"  Total chains to create: {len(chains)}")
    print(f"  Total samples in chains: {sum(len(v['files']) for v in chains.values())}")
    print(f"  Hi-hat chains: {len(hihat_chains)}")
    print(f"  Regular chains: {len(regular_chains)}")
    
    # Generate preview markdown summary
    print("\nüìù Generating preview markdown summary...")
    preview_file = Path("DRY_RUN_SUMMARY.md")
    # Convert chains dict to list format for markdown generation
    preview_chains = []
    for chain_key, chain_data in chains.items():
        preview_chains.append({
            'name': chain_key,
            'chain': chain_data,
            'metadata': chain_data['metadata'],
            'original_files': chain_data.get('files', [])  # Add the files for markdown generation
        })
    _generate_markdown_summary(preview_chains, preview_file, input_dir)
    print(f"  ‚úÖ Generated preview summary: {preview_file}")
    
    return {
        'status': 'dry_run',
        'total_chains': len(chains),
        'hihat_chains': len(hihat_chains),
        'regular_chains': len(regular_chains)
    }

def process_audio_directory(input_dir: str, output_dir: str, dry_run: bool = False) -> Dict[str, Any]:
    """
    Process audio files from input directory and create sample chains.
    
    Args:
        input_dir: Input directory containing audio files
        output_dir: Output directory for generated chains
        dry_run: If True, only show what would be created
        
    Returns:
        Dictionary with processing results
    """
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    if not input_path.exists():
        raise FileNotFoundError(f"Input directory not found: {input_dir}")
    
    # Load configuration
    config = SampleChainConfig()
    max_samples = config.max_samples_per_chain
    
    print(f"‚öôÔ∏è  Max samples per chain: {max_samples}")
    
    # Find audio files (excluding Loops folder)
    audio_files = []
    for pattern in ['*.wav', '*.aiff', '*.flac', '*.mp3']:
        for file_path in input_path.rglob(pattern):
            if 'loops' not in str(file_path).lower():
                audio_files.append(file_path)
    
    if not audio_files:
        raise ValueError(f"No audio files found in '{input_dir}'")
    
    print(f"üìÅ Found {len(audio_files)} audio files, filtered out {len([f for f in input_path.rglob('*') if 'loops' in str(f).lower() and f.is_file()])} (Loops), processing {len(audio_files)}")
    
    if dry_run:
        return _dry_run_processing(audio_files, config, input_dir)
    
    print(f"üìÅ Processing {len(audio_files)} audio files...")
    
    # Create output directory and chains subfolder
    output_path.mkdir(parents=True, exist_ok=True)
    chains_path = output_path / "chains"
    chains_path.mkdir(exist_ok=True)
    
    # Plan sample chains
    print("üìã Planning sample chains...")
    planner = SmartChainPlanner(config)
    sample_chains = planner.plan_smart_chains(audio_files)
    
    print(f"üìä Created {len(sample_chains)} sample chains")
    
    # Build sample chains
    print("üî® Building sample chains...")
    builder = SampleChainBuilder({
        'output_sample_rate': 48000,
        'output_bit_depth': 16,
        'output_channels': 2,
        'max_samples_per_chain': max_samples
    })
    
    built_chains = []
    for chain_key, chain_data in sample_chains.items():
        print(f"  üìÅ Building {chain_key}...")
        
        # Convert file paths to Path objects if they're strings
        file_paths = []
        for file_path in chain_data['files']:
            if isinstance(file_path, str):
                file_paths.append(Path(file_path))
            else:
                file_paths.append(file_path)
        
        try:
            built_chain = builder.build_sample_chain(file_paths, chain_key)
            built_chains.append({
                'name': chain_key,
                'chain': built_chain,
                'metadata': chain_data['metadata'],
                'files': chain_data['files'],
                'original_files': chain_data['files']  # Keep original file paths for markdown
            })
            print(f"    ‚úÖ Built successfully")
        except Exception as e:
            print(f"    ‚ùå Failed to build: {e}")
            continue
    
    if not built_chains:
        raise RuntimeError("No sample chains were built successfully")
    
    # Export chains
    print("üì§ Exporting sample chains...")
    exporter = ChainExporter()
    
    for chain_data in built_chains:
        print(f"  üìÅ Exporting {chain_data['name']}...")
        try:
            exporter.export_chain(
                chain_data['chain'],
                chains_path,
                chain_data['metadata'],
                root_metadata_dir=output_path / "metadata"
            )
            print(f"    ‚úÖ Exported successfully")
        except Exception as e:
            print(f"    ‚ùå Failed to export: {e}")
            continue
    
    # Create metadata folder
    print("üìÅ Creating metadata folder...")
    metadata_dir = output_path / "metadata"
    metadata_dir.mkdir(exist_ok=True)
    
    # Save chain configuration
    chain_config = {
        'configuration': {
            'max_samples_per_chain': max_samples
        },
        'chains': [chain['metadata'] for chain in built_chains]
    }
    
    with open(metadata_dir / "chain_config.yaml", 'w') as f:
        yaml.dump(chain_config, f, default_flow_style=False, indent=2)
    print(f"  ‚úÖ Saved config to {metadata_dir}/chain_config.yaml")
    
    # Generate markdown summary in root output directory
    print("üìù Generating markdown summary...")
    summary_path = output_path / "CHAIN_SUMMARY.md"
    _generate_markdown_summary(built_chains, summary_path, input_dir)
    print(f"  ‚úÖ Generated summary: {summary_path}")
    
    print("‚úÖ Processing completed successfully!")
    print(f"üìÅ Output structure:")
    print(f"  üìÇ Main output: {output_path}")
    print(f"  üéµ Sample chains: {chains_path}")
    print(f"  üìã Metadata: {output_path}/metadata")
    
    return {
        'status': 'completed',
        'input_files': len(audio_files),
        'output_chains': len(built_chains),
        'output_directory': str(output_path),
        'chains_directory': str(chains_path)
    }

@click.command()
@click.argument('input_dir', type=click.Path(exists=True, file_okay=False, dir_okay=True))
@click.argument('output_dir', type=click.Path(file_okay=False, dir_okay=True))
@click.option('--verbose', '-v', is_flag=True, help='Verbose output')
@click.option('--dry-run', is_flag=True, help='Show what would be processed without doing it')
@click.option('--config', type=click.Path(exists=True, file_okay=True, dir_okay=False),
              help='Configuration file path')
def main(
    input_dir: str,
    output_dir: str,
    verbose: bool,
    dry_run: bool,
    config: Optional[str]
) -> None:
    """
    NI Sample Chainer - Create evenly spaced sample chains from WAV files.
    
    Processes audio files in INPUT_DIR and creates sample chains in OUTPUT_DIR,
    optimized for the Elektron Digitakt 2 sampler.
    """
    
    # Display banner
    if verbose:
        print("üéµ NI Sample Chainer v0.1.0")
        print("=" * 50)
    
    # Validate input directory
    input_path = Path(input_dir)
    if not input_path.exists():
        click.echo(f"‚ùå Error: Input directory '{input_dir}' does not exist.", err=True)
        sys.exit(1)
    
    # Check for audio files
    audio_files = []
    for ext in ["*.wav", "*.flac", "*.aiff", "*.mp3"]:
        audio_files.extend(input_path.rglob(ext))
    
    if not audio_files:
        click.echo(f"‚ùå Error: No audio files found in '{input_dir}' or its subdirectories", err=True)
        click.echo("Supported formats: WAV, FLAC, AIFF, MP3", err=True)
        sys.exit(1)
    
    if verbose:
        print(f"üìÅ Found {len(audio_files)} audio files in input directory")
    
    # Create output directory if it doesn't exist
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    if verbose:
        print(f"üìÅ Output directory: {output_path.absolute()}")
    
    # Configuration summary
    if verbose:
        print("‚öôÔ∏è  Configuration:")
        print("   Quality: standard")
        print("   Parallel processes: 4")
        print()
    
    # Dry run mode
    if dry_run:
        print("üîç DRY RUN MODE - No files will be processed")
        print("=" * 60)
        try:
            # Get filtered audio files (same logic as main processing)
            input_path = Path(input_dir)
            audio_files = []
            total_found = 0
            filtered_out = 0
            
            for ext in ["*.wav", "*.flac", "*.aiff", "*.mp3"]:
                # Find all audio files
                found_files = input_path.rglob(ext)
                # Filter out files in Loops folders
                for file_path in found_files:
                    total_found += 1
                    # Check if any part of the path contains "Loops" (case-insensitive)
                    if 'loops' not in [part.lower() for part in file_path.parts]:
                        audio_files.append(file_path)
                    else:
                        filtered_out += 1
                        if verbose:
                            print(f"  üö´ Filtered out (Loops): {file_path}")
            
            print(f"üìÅ Found {total_found} audio files, filtered out {filtered_out} (Loops), processing {len(audio_files)}")
            
            config = SampleChainConfig()
            planner = SmartChainPlanner(config)
            sample_chains = planner.plan_smart_chains(audio_files)
            
            print(f"üìä Would create {len(sample_chains)} sample chains:")
            print()
            
            # Group chains by type
            hihat_chains = {k: v for k, v in sample_chains.items() if k.startswith('hats')}
            regular_chains = {k: v for k, v in sample_chains.items() if not k.startswith('hats')}
            
            # Display hi-hat chains
            if hihat_chains:
                print("\nü•Å HI-HAT CHAINS (with closed/open interleaving):")
                print("-" * 50)
                for chain_key, chain_data in hihat_chains.items():
                    metadata = chain_data['metadata']
                    actual_samples = metadata.get('sample_count', 0)
                    chain_samples = metadata.get('chain_samples', actual_samples)
                    estimated_size = metadata.get('estimated_file_size_mb', 0)
                    actual_duration = metadata.get('estimated_duration_seconds', 0)
                    
                    print(f"  {chain_key}: {actual_samples} samples")
                    print(f"    Closed: {metadata.get('closed_count', 0)}, Open: {metadata.get('open_count', 0)}")
                    print(f"    Hat names: {', '.join(metadata.get('hat_names', []))}")
                    print(f"    Est. size: {estimated_size}MB")
                    print(f"    Longest sample: {actual_duration:.2f}s")
                    
                    # Show first few files
                    files = chain_data.get('files', [])
                    for i, file_path in enumerate(files[:4]):
                        file_name = file_path.name if hasattr(file_path, 'name') else str(file_path).split('/')[-1]
                        is_hihat, hihat_type = config.is_hihat_file(Path(str(file_path)))
                        icon = "üîí" if hihat_type == 'closed' else "üîì"
                        print(f"      {i+1}. {icon} {file_name}")
                    if len(files) > 4:
                        print(f"      ... and {len(files)-4} more files")
                    print()
            
            # Display regular chains
            if regular_chains:
                print("üéµ REGULAR CHAINS (by directory structure):")
                print("-" * 50)
                for chain_key, chain_data in sorted(regular_chains.items()):
                    metadata = chain_data['metadata']
                    sample_count = metadata['sample_count']
                    estimated_size = metadata.get('estimated_file_size_mb', 0)
                    
                    print(f"  {chain_key}: {sample_count} samples")
                    print(f"    Est. size: {estimated_size}MB")
                    
                    # Show first few files
                    for i, file_path in enumerate(chain_data['files'][:3], 1):
                        filename = Path(file_path).name
                        print(f"      {i}. {filename}")
                    
                    if len(chain_data['files']) > 3:
                        print(f"      ... and {len(chain_data['files']) - 3} more files")
                    print()
            
            # Summary statistics
            total_samples = sum(len(chain['files']) for chain in sample_chains.values())
            print("üìà SUMMARY:")
            print(f"  Total files to process: {len(audio_files)}")
            print(f"  Total chains to create: {len(sample_chains)}")
            print(f"  Total samples in chains: {total_samples}")
            print(f"  Hi-hat chains: {len(hihat_chains)}")
            print(f"  Regular chains: {len(regular_chains)}")
            
            # Generate preview markdown summary
            print("\nüìù Generating preview markdown summary...")
            preview_file = Path("DRY_RUN_SUMMARY.md")
            # Convert sample_chains dict to list format for markdown generation
            preview_chains = []
            for chain_key, chain_data in sample_chains.items():
                preview_chains.append({
                    'name': chain_key,
                    'chain': chain_data,
                    'metadata': chain_data['metadata'],
                    'original_files': chain_data.get('files', [])
                })
            _generate_markdown_summary(preview_chains, preview_file, input_dir)
            print(f"  ‚úÖ Generated preview summary: {preview_file}")
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not analyze sample chains: {e}")
            print("Falling back to basic file list...")
            print(f"Would process {len(audio_files)} files:")
            for file in audio_files[:5]:  # Show first 5 files
                print(f"  - {file.name}")
            if len(audio_files) > 5:
                print(f"  ... and {len(audio_files) - 5} more files")
        
        return
    
    # Process audio files
    try:
        result = process_audio_directory(
            input_dir=input_dir,
            output_dir=output_dir,
            dry_run=dry_run
        )
        
        if result['status'] == 'completed':
            click.echo("‚úÖ Processing completed successfully!")
        else:
            click.echo(f"‚ö†Ô∏è  Processing completed with status: {result['status']}")
            
    except Exception as e:
        click.echo(f"‚ùå Error during processing: {e}", err=True)
        if verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    import click
    main()



